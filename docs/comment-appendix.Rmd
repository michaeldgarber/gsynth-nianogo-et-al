---
title: "Appendix for comment on Nianogo et al."
author: "Michael D. Garber"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_depth: 4
---

```{r,eval=T, echo=F,warning=FALSE, message=F}
library(here)
library(tidyverse)
library(mapview) #for interactive mapping
library(tmap) #static mapping
library(sf) #for managing spatial data
library(gsynth) #to run the generalized synthetic control method
library(RColorBrewer) #for creating color palettes
```

# Introduction
This appendix contains supporting information and code related to my comment on Nianogo et al.'s article.

The R Markdown file that creates this web page is located here:
https://github.com/michaeldgarber/gsynth-nianogo-et-al/blob/main/docs/comment-appendix.Rmd


The authors provide their data and code here:
https://anonymous.4open.science/r/Medicaid-CVD-Disparities-4CB7/README.md

I've done some additional processing to that data in the scripts located in this folder:
https://github.com/michaeldgarber/gsynth-nianogo-et-al/tree/main/scripts

Those scripts can be run in the following order:
```{r, eval=F, echo=T,warning=FALSE, message=F}
source(here("scripts", "read-wrangle-data-acs.R"))
source(here("scripts", "read-wrangle-data-pres-election.R"))
source(here("scripts", "read-wrangle-data-nianogo-et-al.R"))
```


# Exploring data
```{r, eval=T, echo=F,warning=FALSE, message=F}
#Load the data. Don't show this code chunk in the html.
#Note these data are created here:
setwd(here("data","data-processed"))
load("black_complete.RData")
load("hispanic_complete.RData")
load("black_complete_geo.RData")
load("hispanic_complete_geo.RData")
load("white.RData")
load("overall.RData")
load("overall_geo.RData")
load("overall_covars_alt.RData")
load("lookup_state_abb_geo.RData")
load("lookup_state_abb_geo_simplify_shift_al_hi.RData")
```

## Medicaid expansion and missingness
In this section, I explore Medicaid expansion status by missingness status in the demographic groups.

### Medicaid expansion (all states, 2019)
This map shows Medicaid expansion status of states in 2019.
```{r,eval=T, echo=F, warning=FALSE, message=F}
overall %>%
  filter(year==2019) %>% 
  group_by(treated) %>% 
  summarise(n=n()) %>% 
  knitr::kable(caption="Medicaid expansion status (2019)")
```

```{r,eval=T, echo=F, warning=FALSE, message=F}
#Create color palettes for maps
pal_puor_4=brewer.pal(name="PuOr",n=4)
pal_puor_4_subset=pal_puor_4[c(1,2,4)]
pal_puor_4_reorder = c(pal_puor_4_subset,pal_puor_4[3])
pal_puor_2=pal_puor_4_reorder[c(1,3)]
#pal_puor_2 %>% swatch()

lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2019) %>% 
  mutate(treated_y_n=case_when(
    treated==1~"Yes",
    TRUE ~"No")) %>% 
  tm_shape()+
  tm_fill(
    "treated_y_n",
    palette = pal_puor_2,
    title="Medicaid expansion status (2019)")+
  tm_borders(col="black",alpha=.5)+
  tm_layout(
    frame=F,
    legend.outside=T,
    legend.outside.position="bottom"
  )
```


### Hispanic population
```{r,eval=T, echo=F,warning=FALSE, message=F}
#Number of non-missing states
hispanic_complete %>%
  filter(year==2019) %>% 
  group_by(treated) %>% 
  summarise(n=n()) %>% 
  knitr::kable(caption="Medicaid expansion status (2019) among states with non-missing CVD data for the Hispanic population")

lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2019) %>% 
  tm_shape()+
  tm_fill(
    "treated_post_hispanic_miss",
    palette=pal_puor_4_reorder,
    title="Medicaid expansion status (2019) by missingness in Hispanic data")+
  tm_borders(col="black",alpha=1)+
  tm_layout(
    frame=F,
#    legend.title.size=.5,
    legend.outside=T,
    legend.outside.position="bottom"
    )

```

### Black population
```{r,eval=T, echo=F, warning=FALSE, message=F}
black_complete %>%
  filter(year==2019) %>% 
  group_by(treated) %>% 
  summarise(n=n()) %>% 
  knitr::kable(caption="Medicaid expansion status (2019) among states with non-missing CVD data for the Black population")

lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2019) %>% 
  tm_shape()+
  tm_fill(
    "treated_post_black_miss",
    palette=pal_puor_4_reorder,
    title="Medicaid expansion status (2019) by missingness in Black data")+
  tm_borders(col="black",alpha=1)+
  tm_layout(
    frame=F,
#    legend.title.size=.5,
    legend.outside=T,
    legend.outside.position="bottom"
    )

```

## Distribution of BRFSS covariates
In this section, I examine the distribution of some of the BRFSS covariates used in the analysis to see if the BRFSS data may be contributing to the instability of the effect estimates.

### Proportion men
#### All adults aged 45-64
Proportion men among all adults aged 45-64 (dataset name: overall)
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$male)
overall %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

#### Hispanic adults aged 45-64
Proportion men among Hispanic adults aged 45-64 (dataset name: hispanic_complete)

Observation: some state-years have 0% or 100% men in this group, which is not plausible, highlighting the fact that BRFSS may not be reliable in such stratified sub-groups.
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$male)
hispanic_complete %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

In California, most years seem implausibly low.
```{r,eval=T, echo=F, warning=FALSE, message=F}
hispanic_complete %>% 
  filter(state_abb=="CA") %>% 
  ggplot(aes(y=male,x=year))+
  geom_line()+
  theme_bw()
```

#### Black adults aged 45-64
Again, the proportion men among Black adults aged 45-64 seems implausible in some state-years.
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$male)
black_complete %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$male)
white %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

### Low income
Less than $15,000

#### All adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$low_income)
overall %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```


#### Hispanic adults aged 45-64
Again, there are what I would think are some implausible observations (e.g,. 0% or 100% low income in a state-year).
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$low_income)
hispanic_complete %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```

#### Black adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$low_income)
black_complete %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$low_income)
white %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```

### Low education
No high-school degree
#### All adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$low_educ)
overall %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```


#### Hispanic adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$low_educ)
hispanic_complete %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```

#### Black adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$low_educ)
black_complete %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$low_educ)
white %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```


### Married

#### All adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$married)
overall %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```


#### Hispanic adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$married)
hispanic_complete %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```

#### Black adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$married)
black_complete %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$married)
white %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```

### Political orientation and considering an alternative measure
In Nianogo et al.'s Table 1, they present the measure of political-party affiliation in 2014.
The below replicates those values, where 0=Republican, 1=Democrat, and 2=Split.

```{r,eval=T, echo=F, warning=FALSE, message=F}
overall %>% 
  filter(year==2014) %>% 
  group_by(party) %>% 
  summarise(
    n=n()) %>% 
  ungroup() %>% 
  mutate(
    n_total=sum(n),
    prop=n/n_total
    ) %>% 
  knitr::kable()
```

To facilitate interpretation, this variable in 2016 is mapped here:
```{r,eval=T, echo=F, warning=FALSE, message=F}
lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2016) %>%
  mutate(
    party_overall_char=case_when(
      party_overall==0~"Republican",
      party_overall==1~"Democrat",
      party_overall==2~"Split"
  )) %>% 
  tm_shape()+
  tm_fill(
    "party_overall_char",
    palette=c("#67a9cf","#ef8a62","#af8dc3"),
    title="Political party variable (2016)"
)+
  tm_borders(col="black",alpha=.5)+
  tm_layout(
    frame=F,
    legend.outside=T,
    legend.outside.position="bottom"
  )

```

These values struck me as somewhat odd. For one, it appears a given state-year receives a value of either Republican, Democrat, or split, raising the question of within-state variability in the measure. Second, given the polarization and parity of party politics in the United States, I would expect the values corresponding to Republican (0) and Democrat (1) to be about the same and for both to be nearer to 50%.

A simpler and more stable (in terms of sampling variability) measure for the state's political environment might be the popular-vote share from presidential elections. Those data are available here:

https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX

In this script, I've loaded popular-vote data from presidential elections.
```{r,eval=F}
source(here("scripts", "read-wrangle-data-pres-election.R"))
```

In analyses as presented in Scenarios 2-5 in the main text, I applied the vote share from the most recent election if the year wasn't an election year. For example, 2014 received 2012's popular-vote data.


# Using state-year effect estimates to calculate various summary measures
In this section, I show how state-year effect estimates generated by the `gsynth()` function can be used to calculate summary measures of effect. Specifically, in this section, I populate some values corresponding to Scenarios 4 and 5 in the main text's table.

Code that generates other results can be found here:
gsynth-nianogo-et-al/scripts/gsynth-analyses-to-post.R

## Load the data
```{r, eval=F, echo=T,warning=FALSE, message=F}
source(here("scripts", "read-wrangle-data-acs.R"))
source(here("scripts", "read-wrangle-data-pres-election.R"))
source(here("scripts", "read-wrangle-data-nianogo-et-al.R"))
```

```{r, eval=T, echo=F,warning=FALSE, message=F}
#Load the gsynth output in the background
setwd(here("data","data-processed"))
load("gsynth_out_overall_sub_pol_mc_nnm.RData")
```

## Run the gsynth function
Here, I will summarize effects estimated by the MC-NNM estimator as presented in Scenarios 4 and 5 of the table in the text.

For more information on the syntax of the `gsynth()` function, please see:
https://yiqingxu.org/packages/gsynth/articles/tutorial.html#matrix-completion

```{r, eval=F, echo=T,warning=FALSE, message=F}
gsynth_out_overall_sub_pol_mc_nnm=gsynth(
  #syntax: outcome ~ treatment indicator+ covariates
  cvd_death_rate ~ treatedpost + 
    primarycare_rate +
    cardio_rate + 
    population_overall + 
    low_educ_overall + 
    married_overall+ 
    employed_for_wages_overall + 
    vote_share_dem+#popular vote data
    low_income_overall + 
    male_overall + 
    race_nonwhite_overall
  ,

  #dataset in which the effects are estimated
  data = overall_covars_alt,
  estimator = "mc", #the MC-NNM estimator
  #      EM = F, #
  index = c("state_id","year"), #time-unit
  
  #non-parametric bootstrap if MC-NNM estimator used
  #inference = "parametric", 
  se = TRUE, 
  
  #perform a cross-validation procedure to 
  #determine the number of unobserved factors
  CV = TRUE, 

  #the range of possible numbers of unobserved factors
  r = c(0, 5), #
  seed = 123, #arbitrary seed so same results every time
  nboots = 2000, #number of bootstrap reps
  force = "two-way", 
  parallel = TRUE
)
```


## Examine summary output returned by the gsynth function
### Average treatment effect with confidence intervals
Return the average (unweighted) difference effect over all treated state-years and the corresponding standard error and confidence intervals.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$est.avg
```

These confidence intervals are calculated by adding 1.96*SE and -1.96*SE to either side of the estimate.
```{r}
#qnorm(.975)#return the exact value
#Estimate
gsynth_out_overall_sub_pol_mc_nnm$est.avg[1]

#Upper limit
gsynth_out_overall_sub_pol_mc_nnm$est.avg[1]+
  gsynth_out_overall_sub_pol_mc_nnm$est.avg[2]*1.959964

#Lower limit
gsynth_out_overall_sub_pol_mc_nnm$est.avg[1]-
  gsynth_out_overall_sub_pol_mc_nnm$est.avg[2]*1.959964
```

### Average treatment effect - point estimate only
Another way to return the point estimate for the average treatment effect (without the confidence intervals) is by `gsynth_object$att.avg`.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$att.avg
```



### Average treatment effect at each time point
The average treatment effect at each time point can be returned by `gsynth_object$att`. These effect estimates are summarized by time over units where time is indexed from the treatment period for that unit such that the first treated time point is time 1. By the numbering system below, time 0 is the latest time point of the pre-treatment period.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$att
```

## Calculate unweighted average difference effect by summarizing effect estimates in every treated state-year


### Return effect estimates for every treated state-year
Using the effect estimates for every treated state-year, we can replicate the summary difference effects presented above. Effect estimates for every treated state-year are returned by `gsynth_objecct$eff`.

Here are the difference effects for all state-years. Note that "effects" are estimated for all state-years in the treated states, including pre-treatment years. Pre-treatment effects are not really effects but are the pre-treatment prediction error for treated units: the difference between the observed and predicted counterfactual outcomes before treatment.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$eff
```

### Wrangle state-year effect estimates in easier-to-read form
Do some data wrangling to the effect estimates to summarize them.

Notes on my naming conventions for the object:

* tib: for tibble
* diff_eff_by_state_year: difference effects by state-year
* mc_nnm: to indicate which gsynth model it corresponds to

Also note that these results are among the total population ("overall"), not a particular demographic subgroup.
```{r}
tib_diff_eff_by_state_year_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$eff %>% 
  as_tibble() %>% #Convert to tibble
  mutate(year=row_number()+1999)  %>% #Add 1999 to row number to calculate year
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>%  #make the dataset long-form
  #Rename some of the columns
  rename(
    state_id = name,
    diff_pt = value #estimated difference effect
    ) %>% 
  mutate(state_id=as.numeric(state_id)) #make sure state_id is numeric

tib_diff_eff_by_state_year_mc_nnm
```

Before we summarize these difference effect estimates, we can link in the treatment indicator so that we know whether the difference effects are during the post-treatment period. The treatment indicator is obtained by calling `gsynth_object$D.tr.` 

(The letter D is conventionally used in the econometrics literature to denote the treatment status.)

```{r}
tib_treatedpost =gsynth_out_overall_sub_pol_mc_nnm$D.tr %>% 
  as_tibble() %>%
  mutate(year=row_number()+1999) %>% 
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>% 
  rename(
    state_id = name,
    treatedpost = value) %>% 
  mutate(state_id=as.numeric(state_id))

tib_treatedpost
```

### Calculate unweighted average difference effect 
Now we can link those two together to summarize the difference effects over the post-treatment period (which varies by state). It should match the average treatment effect obtained above.

```{r}
diff_pt_mean_mc_nnm=tib_diff_eff_by_state_year_mc_nnm %>% 
  #Link the treatment indicator to the difference effects by state-year
  left_join(tib_treatedpost,by=c("state_id","year")) %>%
  group_by(treatedpost) %>% 
  #take the simple mean by treatment indicator
  summarise(
    diff_pt_mean=mean(diff_pt,na.rm=T)
  )

diff_pt_mean_mc_nnm
```

The average difference effect post-treatment indeed matches the value returned by `gsynth_object$att.avg`, which demonstrates that the average treatment effect returned by the gsynth's default output is the unweighted average over treated state-years.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$att.avg
```

### Calculate 95% confidence intervals for the unweighted average difference effect using the bootstrap replicates.

First, return bootstrapped effect estimates for every state-year in every replicate by calling `gsynth_object$eff.boot`.

```{r}
tib_eff_boot_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$eff.boot %>% 
  #converting to tibble makes the data such that there
  #are 20 rows and 6,800 columns, each with information
  #containing the bootstrapped effect estimates.
  #We need to organize the data such that each row
  #represents a unit-month-bootstrap replicate
  as_tibble() %>% 
  #Note each row represents the time variable.
  #The observation period begins in 2000, so 
  #we should add 1999 to the row number to get the first obs
  #to be 2000
  mutate(year=row_number()+1999) %>% 
  #make year the left-most variable to make it easier to see
  dplyr::select(year,everything()) %>% 
  #now make the data long form
  pivot_longer(cols=-year) %>% 
  #we now have three variables: year, name, and value.
  #the "name" variable contains the state id and the bootstrap
  #replicate. We need to separate these two values into separate variables.
  #We can use separate_wider_delim() for this from tidyr
  separate_wider_delim(name,names=c("state_id","boot_rep"), ".") %>% 
  #make the state_id and boot_rep (boot replication) variables numeric
  mutate(
    state_id=as.numeric(state_id),
    boot_rep_char=str_sub(boot_rep, 5,11),#5 to 11 in case lots of digits
    boot_rep=as.numeric(boot_rep_char)
  ) %>% 
  dplyr::select(-boot_rep_char) %>%   #drop vars not needed
  #note the difference-based effect estimate is stored in "value"
  #let's call it diff_boot
  rename(diff_boot =value)

tib_eff_boot_mc_nnm
```

Perform some checks on this dataset. The number of rows should equal the number of bootstrap replicates times the number of years times the number of states.

We specified 2,000 boostrap replicates in the `gsynth()` function above.

There are 34 states included in the analysis.
```{r}
n_distinct(tib_eff_boot_mc_nnm$state_id)
```

And there are 20 years included in the analysis.
```{r}
n_distinct(tib_eff_boot_mc_nnm$year)
```

So the number of rows should equal
```{r}
2000*n_distinct(tib_eff_boot_mc_nnm$state_id)*n_distinct(tib_eff_boot_mc_nnm$year)
```

Does it?
```{r}
nrow(tib_eff_boot_mc_nnm)
```
Yes.

Now we can summarize these bootstrapped difference effects to calculate 95% confidence intervals. The process for this is to first calculate average treatment effects for each of the 2,000 bootstrap replicates and then find the 2.5th and 97.5th percentiles over those replicates.

```{r}
diff_boot_mean_mc_nnm=tib_eff_boot_mc_nnm %>% 
  #First calculate average treatment effects for each replicate
  left_join(tib_treatedpost,by=c("state_id","year")) %>%
  group_by(boot_rep, treatedpost) %>% 
  summarise(
    diff_boot_mean=mean(diff_boot,na.rm=T)
  ) %>% 
  ungroup() %>% 
  #We can filter to treatedpost==1 - no need for the pre-treatment effects
  filter(treatedpost==1) %>% 
  #Now find the 2.5th and 97.5th value
  group_by(treatedpost) %>% 
  summarise(
    diff_pt_ll=quantile(diff_boot_mean, probs=0.025, na.rm=TRUE),
    diff_pt_ul=quantile(diff_boot_mean,probs=.975,na.rm=TRUE)
  )

diff_boot_mean_mc_nnm
```
Those are the confidence intervals corresponding to the overall estimate in Scenario 4 in the table in the main text.


## Calculate unweighted average ratio effects
### Point estimates
Ratio effects can also be calculated using this method by comparing the predicted counterfactual outcomes in the treated (`gsynth_object$Y.ct`) with the actual outcomes (`gsynth_object$Y.tr`).

```{r}
#actual outcome in treated
tib_y_tr_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$Y.tr %>% 
  as_tibble() %>%
  mutate(year=row_number()+1999) %>% 
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>% 
  rename(
    state_id = name,
    y_tr_pt = value #observed treated value, pt for point estimate
  ) %>% 
  mutate(state_id =as.numeric(state_id))
  
  
# Counterfactual outcome in treated
tib_y_ct_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$Y.ct %>% 
  as_tibble() %>%
  mutate(year=row_number()+1999) %>% 
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>% 
  rename(
    state_id = name,
    y_ct_pt = value#estimated counterfactual value, pt for point estimate
  ) %>% 
  mutate(state_id =as.numeric(state_id))
```

Link them together with the treatment-status indicator and find differences and ratios
```{r}
tib_mc_nnm=tib_treatedpost %>% 
  left_join(tib_y_tr_mc_nnm,by=c("year","state_id")) %>% 
  left_join(tib_y_ct_mc_nnm,by=c("year","state_id")) %>% 
  left_join(tib_diff_eff_by_state_year_mc_nnm,by=c("year","state_id")) %>% 
  #Check to make sure that the difference calculated
  #by subtracting the observed outcome from the counterfactual outcome
  #is the same as the reported state-year effect estimates. 
  #Rename the difference effect reported by .eff
  rename(diff_pt_report=diff_pt) %>% 
  #Calculate differences and ratios
  mutate(
      diff_pt=y_tr_pt-y_ct_pt,#difference effect (point estimate)
      ratio_pt=y_tr_pt/y_ct_pt, #Ratio effect (point estimate)
      
#      As a check, are these the same?
      diff_pt_check=diff_pt_report-diff_pt

  )
  

tib_mc_nnm
```

As a check on these calculations, `diff_pt_check` should be zero in all observations
```{r}
summary(tib_mc_nnm$diff_pt_check)
```


Okay, now we can calculate average ratio effects in the treated over treated state-years. Note that we are not simply summarizing the state-year ratio effects as the arithmetic mean of ratios is not generally the same as the ratio of arithmetic means. We can find the summary ratio effect by finding the mean of treated counterfactual outcomes in the treated state-years and the mean of observed outcomes in the treated state-years and then taking the ratio of the two means.

```{r}
ratio_pt_mc_nnm=tib_mc_nnm %>% 
  filter(treatedpost==1) %>% 
  group_by(treatedpost) %>% 
  summarise(
    y_tr_pt_mean=mean(y_tr_pt,na.rm=T),#observed treated value
    y_ct_pt_mean=mean(y_ct_pt,na.rm=T),#counterfactual 
  ) %>% 
  ungroup() %>% 
  mutate(
    ratio_pt_mean=y_tr_pt_mean/y_ct_pt_mean #ratio effect, point estimate
  )

ratio_pt_mc_nnm
```

This estimated ratio effect of 0.99 corresponds to the reported overall ratio effect for scenario 4 in the table in the main text.


### Confidence intervals
As we did for difference effects, we can calculate confidence intervals around this ratio effect by calculating the ratio effect in each bootstrap replicate and then finding the 2.5th and 97.5th percentiles over replicates.

In each replicate, we can calculate the estimated counterfactual outcome by subtracting the bootstrap's difference effect from the observed outcome. 
```{r}
#We can work from the previous tibble we created corresponding to the difference-based 
#bootstrapped effect estimates
ratio_ci_mc_nnm=tib_eff_boot_mc_nnm %>% 
  left_join(tib_mc_nnm,by=c("state_id","year")) %>% #link in the data just above
  filter(treatedpost==1) %>% #limit to treated observations
  mutate(
    y_ct_boot=y_tr_pt-diff_boot #counterfactual estimate - bootstrap
  ) %>% 
  #now calculate summary ratio effect in each replicate
  group_by(boot_rep, treatedpost) %>% 
  summarise(
      y_tr_pt_mean=mean(y_tr_pt,na.rm=T),#observed treated value, mean (doesn't vary by boot rep)
      y_ct_boot_mean=mean(y_ct_boot,na.rm=T)
  ) %>% 
  ungroup() %>% 
  mutate(
    ratio_boot_mean=y_tr_pt_mean/y_ct_boot_mean
  ) %>% 
    #Now return the 95% confidence intervals of the mean bootstrapped 
  #difference effect over replicates
  group_by(treatedpost) %>% 
  summarise(
      ratio_pt_ll=quantile(ratio_boot_mean, probs=0.025, na.rm=TRUE),
      ratio_pt_ul=quantile(ratio_boot_mean,probs=.975,na.rm=TRUE)
  )


```

Ratio effect point estimate
```{r}
ratio_pt_mc_nnm
```

Ratio effect 95% CI
```{r}
ratio_ci_mc_nnm
```



## Assess model fit before treatment
We can also assess model fit before treatment using the difference-based "effect" estimates before treatment. Before treatment, these differences are not effects but are the pre-treatment prediction error.

In the main text of the table, I used mean absolute error to measure model fit. Mean squared error or root mean squared error could also be used. I calculate these three measures below.

```{r}
#Let's begin with this tibble, which already contains all of the difference-based
#effect estimates
pre_tx_fit_mc_nnm=tib_mc_nnm %>% 
  mutate(
    #The mean absolute error is the mean of the absolute value of the difference-based
    #effect estimates before treatment.
    diff_pt_abs=abs(diff_pt),

    #To calculate mean squared error, we can first square the difference-based effect
    #estimates and then take the mean
    diff_pt_squared=diff_pt**2 
  ) %>% 
  filter(treatedpost==0) %>% #0 meaning pre-treatment
  group_by(treatedpost) %>% 
  summarise(
    diff_pt_abs_mean=mean(diff_pt_abs,na.rm=T),
    diff_pt_squared_mean=mean(diff_pt_squared,na.rm=T)
  ) %>% 
  mutate(
      #square root the square error
      diff_pt_root_mean_square=sqrt(diff_pt_squared_mean)
  )
```
The mean absolute error of 3.3 corresponds to the reported value for scenario 4 in the table in the main text
```{r}
pre_tx_fit_mc_nnm
```


## Weighted average treatment effects
To do

# Support of miscellaneous statements from text
To do

## Negative predicted counterfactual outomes
I stated in the main text that the minimum pre- dicted value of the counterfactual outcome in the treatment period over the replicates for the Hispanic population in Scenario 2 was −6091 CVD deaths per 100,000 adults.

The below code shows that:


## Implausible demographic values


