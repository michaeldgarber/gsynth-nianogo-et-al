---
title: "Appendix for comment on Nianogo et al."
author: "Michael D. Garber"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_depth: 4
---


# Introduction
This appendix contains supporting information and code related to my comment on Nianogo et al.'s article.

The R Markdown file that creates this web page is located here:
https://github.com/michaeldgarber/gsynth-nianogo-et-al/blob/main/docs/comment-appendix.Rmd


The authors provide their data and code here:
https://anonymous.4open.science/r/Medicaid-CVD-Disparities-4CB7/README.md

I've done some additional processing to that data in the scripts located in this folder:
https://github.com/michaeldgarber/gsynth-nianogo-et-al/tree/main/scripts

Those scripts can be run in the following order:
```{r, eval=F, echo=T,warning=FALSE, message=F}
source(here("scripts", "read-wrangle-data-acs.R"))
source(here("scripts", "read-wrangle-data-pres-election.R"))
source(here("scripts", "read-wrangle-data-nianogo-et-al.R"))
```

Packages used
```{r,eval=T, echo=T, warning=FALSE, message=F}
library(here)
library(tidyverse)
library(mapview) #for interactive mapping
library(tmap) #static mapping
library(sf) #managing spatial data
library(gsynth) #to run the generalized synthetic control method
library(RColorBrewer) #for creating color palettes
library(viridis) #more color palettes
```


# Exploring data
```{r, eval=T, echo=F,warning=FALSE, message=F}
#Load the data. Don't show this code chunk in the html.
#Note these data are created here:
setwd(here("data","data-processed"))
load("black_complete.RData")
load("hispanic_complete.RData")
load("black_complete_geo.RData")
load("hispanic_complete_geo.RData")
load("white.RData")
load("overall.RData")
load("overall_geo.RData")
load("overall_covars_alt.RData")
load("lookup_state_abb_geo.RData")
load("lookup_state_abb_geo_simplify_shift_al_hi.RData")
```

## Medicaid expansion and missingness
In this section, I explore Medicaid expansion status by missingness status in the demographic groups.

### Medicaid expansion (all states, 2019)
This map shows Medicaid expansion status of states in 2019.
```{r,eval=T, echo=F, warning=FALSE, message=F}
overall %>%
  filter(year==2019) %>% 
  group_by(treated) %>% 
  summarise(n=n()) %>% 
  knitr::kable(caption="Medicaid expansion status (2019)")
```

```{r,eval=T, echo=F, warning=FALSE, message=F}
#Create color palettes for maps
pal_puor_4=brewer.pal(name="PuOr",n=4)
pal_puor_4_subset=pal_puor_4[c(1,2,4)]
pal_puor_4_reorder = c(pal_puor_4_subset,pal_puor_4[3])
pal_puor_2=pal_puor_4_reorder[c(1,3)]
#pal_puor_2 %>% swatch()

lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2019) %>% 
  mutate(treated_y_n=case_when(
    treated==1~"Yes",
    TRUE ~"No")) %>% 
  tm_shape()+
  tm_fill(
    "treated_y_n",
    palette = pal_puor_2,
    title="Medicaid expansion status (2019)")+
  tm_borders(col="black",alpha=.5)+
  tm_layout(
    frame=F,
    legend.outside=T,
    legend.outside.position="bottom"
  )
```


### Hispanic population
```{r,eval=T, echo=F,warning=FALSE, message=F}
#Number of non-missing states
hispanic_complete %>%
  filter(year==2019) %>% 
  group_by(treated) %>% 
  summarise(n=n()) %>% 
  knitr::kable(caption="Medicaid expansion status (2019) among states with non-missing CVD data for the Hispanic population")

lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2019) %>% 
  tm_shape()+
  tm_fill(
    "treated_post_hispanic_miss",
    palette=pal_puor_4_reorder,
    title="Medicaid expansion status (2019) by missingness in Hispanic data")+
  tm_borders(col="black",alpha=1)+
  tm_layout(
    frame=F,
#    legend.title.size=.5,
    legend.outside=T,
    legend.outside.position="bottom"
    )

```

### Black population
```{r,eval=T, echo=F, warning=FALSE, message=F}
black_complete %>%
  filter(year==2019) %>% 
  group_by(treated) %>% 
  summarise(n=n()) %>% 
  knitr::kable(caption="Medicaid expansion status (2019) among states with non-missing CVD data for the Black population")

lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2019) %>% 
  tm_shape()+
  tm_fill(
    "treated_post_black_miss",
    palette=pal_puor_4_reorder,
    title="Medicaid expansion status (2019) by missingness in Black data")+
  tm_borders(col="black",alpha=1)+
  tm_layout(
    frame=F,
#    legend.title.size=.5,
    legend.outside=T,
    legend.outside.position="bottom"
    )

```

## Distribution of BRFSS covariates
In this section, I examine the distribution of some of the BRFSS covariates used in the analysis to see if the BRFSS data may be contributing to the instability of the effect estimates.

### Proportion men

#### All adults aged 45-64
Proportion men among all adults aged 45-64 (dataset name: overall)
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$male)
overall %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

#### Hispanic adults aged 45-64
Proportion men among Hispanic adults aged 45-64 (dataset name: hispanic_complete)

Observation: some state-years have 0% or 100% men in this group, which is not plausible, highlighting the fact that BRFSS may not be reliable in such stratified sub-groups.
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$male)
hispanic_complete %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

In California, most years seem implausibly low.
```{r,eval=T, echo=F, warning=FALSE, message=F}
hispanic_complete %>% 
  filter(state_abb=="CA") %>% 
  ggplot(aes(y=male,x=year))+
  geom_line()+
  theme_bw()
```

#### Black adults aged 45-64
Again, the proportion men among Black adults aged 45-64 seems implausible in some state-years.
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$male)
black_complete %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$male)
white %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

### Low income
Less than $15,000

#### All adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$low_income)
overall %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```


#### Hispanic adults aged 45-64
Again, there are what I would think are some implausible observations (e.g,. 0% or 100% low income in a state-year).
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$low_income)
hispanic_complete %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```

#### Black adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$low_income)
black_complete %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$low_income)
white %>% 
  ggplot(aes(x=low_income))+
  geom_histogram()+
  theme_bw()
```

### Low education
No high-school degree

#### All adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$low_educ)
overall %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```


#### Hispanic adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$low_educ)
hispanic_complete %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```

#### Black adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$low_educ)
black_complete %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$low_educ)
white %>% 
  ggplot(aes(x=low_educ))+
  geom_histogram()+
  theme_bw()
```


### Married

#### All adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(overall$married)
overall %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```


#### Hispanic adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$married)
hispanic_complete %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```

#### Black adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(black_complete$married)
black_complete %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```

#### White adults aged 45-64
```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(white$married)
white %>% 
  ggplot(aes(x=married))+
  geom_histogram()+
  theme_bw()
```

### Political orientation and considering an alternative measure
In Nianogo et al.'s Table 1, they present the measure of political-party affiliation in 2014.
The below replicates those values, where 0=Republican, 1=Democrat, and 2=Split.

```{r,eval=T, echo=F, warning=FALSE, message=F}
overall %>% 
  filter(year==2014) %>% 
  group_by(party) %>% 
  summarise(
    n=n()) %>% 
  ungroup() %>% 
  mutate(
    n_total=sum(n),
    prop=n/n_total
    ) %>% 
  knitr::kable()
```

To facilitate interpretation, this variable in 2016 is mapped here:
```{r,eval=T, echo=F, warning=FALSE, message=F}
lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(overall_covars_alt,by="state_abb") %>% 
  filter(year==2016) %>%
  mutate(
    party_overall_char=case_when(
      party_overall==0~"Republican",
      party_overall==1~"Democrat",
      party_overall==2~"Split"
  )) %>% 
  tm_shape()+
  tm_fill(
    "party_overall_char",
    palette=c("#67a9cf","#ef8a62","#af8dc3"),
    title="Political party variable (2016)"
)+
  tm_borders(col="black",alpha=.5)+
  tm_layout(
    frame=F,
    legend.outside=T,
    legend.outside.position="bottom"
  )

```

These values struck me as somewhat odd. For one, it appears a given state-year receives a value of either Republican, Democrat, or split, raising the question of within-state variability in the measure. Second, given the polarization and parity of party politics in the United States, I would expect the values corresponding to Republican (0) and Democrat (1) to be about the same and for both to be nearer to 50%.

A simpler and more stable (in terms of sampling variability) measure for the state's political environment might be the popular-vote share from presidential elections. Those data are available here:

https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX

In this script, I've loaded popular-vote data from presidential elections.
```{r,eval=F}
source(here("scripts", "read-wrangle-data-pres-election.R"))
```

In analyses as presented in Scenarios 2-5 in the main text, I applied the vote share from the most recent election if the year wasn't an election year. For example, 2014 received 2012's popular-vote data.


# Using state-year effect estimates to calculate various summary measures
In this section, I show how state-year effect estimates generated by the `gsynth()` function can be used to calculate summary measures of effect. Specifically, in this section, I populate some values corresponding to Scenarios 4 and 5 in the main text's table.

Code that generates other results can be found here:
gsynth-nianogo-et-al/scripts/gsynth-analyses-to-post.R

## Load the data
```{r, eval=F, echo=T,warning=FALSE, message=F}
source(here("scripts", "read-wrangle-data-acs.R"))
source(here("scripts", "read-wrangle-data-pres-election.R"))
source(here("scripts", "read-wrangle-data-nianogo-et-al.R"))
```

```{r, eval=T, echo=F,warning=FALSE, message=F}
#Load the gsynth output in the background
setwd(here("data","data-processed"))
load("gsynth_out_overall_sub_pol_mc_nnm.RData")
```

## Run the gsynth function
Here, I will summarize effects estimated by the MC-NNM estimator as presented in Scenarios 4 and 5 of the table in the text.

For more information on the syntax of the `gsynth()` function, please see:
https://yiqingxu.org/packages/gsynth/articles/tutorial.html#matrix-completion

```{r, eval=F, echo=T,warning=FALSE, message=F}
gsynth_out_overall_sub_pol_mc_nnm=gsynth(
  #syntax: outcome ~ treatment indicator+ covariates
  cvd_death_rate ~ treatedpost + 
    primarycare_rate +
    cardio_rate + 
    population_overall + 
    low_educ_overall + 
    married_overall+ 
    employed_for_wages_overall + 
    vote_share_dem+#popular vote data
    low_income_overall + 
    male_overall + 
    race_nonwhite_overall
  ,

  #dataset in which the effects are estimated
  data = overall_covars_alt,
  estimator = "mc", #the MC-NNM estimator
  #      EM = F, #
  index = c("state_id","year"), #time-unit
  
  #non-parametric bootstrap if MC-NNM estimator used
  #inference = "parametric", 
  se = TRUE, 
  
  #perform a cross-validation procedure to 
  #determine the number of unobserved factors
  CV = TRUE, 

  #the range of possible numbers of unobserved factors
  r = c(0, 5), #
  seed = 123, #arbitrary seed so same results every time
  nboots = 2000, #number of bootstrap reps
  force = "two-way", 
  parallel = TRUE
)
```


## Examine summary output returned by the gsynth function
### Average treatment effect with confidence intervals
Return the average (unweighted) difference effect over all treated state-years and the corresponding standard error and confidence intervals.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$est.avg
```

These confidence intervals are calculated by adding 1.96*SE and -1.96*SE to either side of the estimate.
```{r}
#qnorm(.975)#return the exact value
#Estimate
gsynth_out_overall_sub_pol_mc_nnm$est.avg[1]

#Upper limit
gsynth_out_overall_sub_pol_mc_nnm$est.avg[1]+
  gsynth_out_overall_sub_pol_mc_nnm$est.avg[2]*1.959964

#Lower limit
gsynth_out_overall_sub_pol_mc_nnm$est.avg[1]-
  gsynth_out_overall_sub_pol_mc_nnm$est.avg[2]*1.959964
```

### Average treatment effect - point estimate only
Another way to return the point estimate for the average treatment effect (without the confidence intervals) is by `gsynth_object$att.avg`.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$att.avg
```



### Average treatment effect at each time point
The average treatment effect at each time point can be returned by `gsynth_object$att`. These effect estimates are summarized by time over units where time is indexed from the treatment period for that unit such that the first treated time point is time 1. By the numbering system below, time 0 is the latest time point of the pre-treatment period.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$att
```

## Calculate unweighted average difference effect by summarizing effect estimates over treated state-years


### Return effect estimates for every treated state-year
Using the effect estimates for every treated state-year, we can replicate the summary difference effects presented above. Effect estimates for every treated state-year are returned by `gsynth_objecct$eff`.

Here are the difference effects for all state-years. Note that "effects" are estimated for all state-years in the treated states, including pre-treatment years. Pre-treatment effects are not really effects but are the pre-treatment prediction error for treated units: the difference between the observed and predicted counterfactual outcomes before treatment.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$eff
```

### Wrangle state-year effect estimates in easier-to-read form
Do some data wrangling to the effect estimates to summarize them.

Notes on my naming conventions for the object:

* tib: for tibble
* diff_eff_by_state_year: difference effects by state-year
* mc_nnm: to indicate which gsynth model it corresponds to

Also note that these results are among the total population ("overall"), not a particular demographic subgroup.
```{r}
tib_diff_eff_by_state_year_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$eff %>% 
  as_tibble() %>% #Convert to tibble
  mutate(year=row_number()+1999)  %>% #Add 1999 to row number to calculate year
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>%  #make the dataset long-form
  #Rename some of the columns
  rename(
    state_id = name,
    diff_pt = value #estimated difference effect
    ) %>% 
  mutate(state_id=as.numeric(state_id)) #make sure state_id is numeric

tib_diff_eff_by_state_year_mc_nnm
```

Before we summarize these difference effect estimates, we can link in the treatment indicator so that we know whether the difference effects are during the post-treatment period. The treatment indicator is obtained by calling `gsynth_object$D.tr.` 

(The letter D is conventionally used in the econometrics literature to denote the treatment status.)

```{r}
tib_treatedpost =gsynth_out_overall_sub_pol_mc_nnm$D.tr %>% 
  as_tibble() %>%
  mutate(year=row_number()+1999) %>% 
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>% 
  rename(
    state_id = name,
    treatedpost = value) %>% 
  mutate(state_id=as.numeric(state_id))

tib_treatedpost
```

### Calculate unweighted average difference effect 
Now we can link those two together to summarize the difference effects over the post-treatment period (which varies by state). It should match the average treatment effect obtained above.

```{r}
diff_pt_mean_mc_nnm=tib_diff_eff_by_state_year_mc_nnm %>% 
  #Link the treatment indicator to the difference effects by state-year
  left_join(tib_treatedpost,by=c("state_id","year")) %>%
  group_by(treatedpost) %>% 
  #take the simple mean by treatment indicator
  summarise(
    diff_pt_mean=mean(diff_pt,na.rm=T)
  )

diff_pt_mean_mc_nnm
```

The average difference effect post-treatment indeed matches the value returned by `gsynth_object$att.avg`, which demonstrates that the average treatment effect returned by the gsynth's default output is the unweighted average over treated state-years.
```{r}
gsynth_out_overall_sub_pol_mc_nnm$att.avg
```

### Calculate 95% confidence intervals for the unweighted average difference effect using the bootstrap replicates.

First, return bootstrapped effect estimates for every state-year in every replicate by calling `gsynth_object$eff.boot`.

```{r}
tib_eff_boot_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$eff.boot %>% 
  #converting to tibble makes the data such that there
  #are 20 rows and 6,800 columns, each with information
  #containing the bootstrapped effect estimates.
  #We need to organize the data such that each row
  #represents a unit-month-bootstrap replicate
  as_tibble() %>% 
  #Note each row represents the time variable.
  #The observation period begins in 2000, so 
  #we should add 1999 to the row number to get the first obs
  #to be 2000
  mutate(year=row_number()+1999) %>% 
  #make year the left-most variable to make it easier to see
  dplyr::select(year,everything()) %>% 
  #now make the data long form
  pivot_longer(cols=-year) %>% 
  #we now have three variables: year, name, and value.
  #the "name" variable contains the state id and the bootstrap
  #replicate. We need to separate these two values into separate variables.
  #We can use separate_wider_delim() for this from tidyr
  separate_wider_delim(name,names=c("state_id","boot_rep"), ".") %>% 
  #make the state_id and boot_rep (boot replication) variables numeric
  mutate(
    state_id=as.numeric(state_id),
    boot_rep_char=str_sub(boot_rep, 5,11),#5 to 11 in case lots of digits
    boot_rep=as.numeric(boot_rep_char)
  ) %>% 
  dplyr::select(-boot_rep_char) %>%   #drop vars not needed
  #note the difference-based effect estimate is stored in "value"
  #let's call it diff_boot
  rename(diff_boot =value)

tib_eff_boot_mc_nnm
```

Perform some checks on this dataset. The number of rows should equal the number of bootstrap replicates times the number of years times the number of states.

We specified 2,000 boostrap replicates in the `gsynth()` function above.

There are 34 states included in the analysis.
```{r}
n_distinct(tib_eff_boot_mc_nnm$state_id)
```

And there are 20 years included in the analysis.
```{r}
n_distinct(tib_eff_boot_mc_nnm$year)
```

So the number of rows should equal
```{r}
2000*n_distinct(tib_eff_boot_mc_nnm$state_id)*n_distinct(tib_eff_boot_mc_nnm$year)
```

Does it?
```{r}
nrow(tib_eff_boot_mc_nnm)
```
Yes.

Now we can summarize these bootstrapped difference effects to calculate 95% confidence intervals. The process for this is to first calculate average treatment effects for each of the 2,000 bootstrap replicates and then find the 2.5th and 97.5th percentiles over those replicates.

```{r}
diff_boot_mean_mc_nnm=tib_eff_boot_mc_nnm %>% 
  #First calculate average treatment effects for each replicate
  left_join(tib_treatedpost,by=c("state_id","year")) %>%
  group_by(boot_rep, treatedpost) %>% 
  summarise(
    diff_boot_mean=mean(diff_boot,na.rm=T)
  ) %>% 
  ungroup() %>% 
  #We can filter to treatedpost==1 - no need for the pre-treatment effects
  filter(treatedpost==1) %>% 
  #Now find the 2.5th and 97.5th value
  group_by(treatedpost) %>% 
  summarise(
    diff_pt_ll=quantile(diff_boot_mean, probs=0.025, na.rm=TRUE),
    diff_pt_ul=quantile(diff_boot_mean,probs=.975,na.rm=TRUE)
  )

diff_boot_mean_mc_nnm
```
Those are the confidence intervals corresponding to the overall estimate in Scenario 4 in the table in the main text.


## Calculate unweighted average ratio effects
### Point estimates
Ratio effects can also be calculated using this method by comparing the predicted counterfactual outcomes in the treated (`gsynth_object$Y.ct`) with the actual outcomes (`gsynth_object$Y.tr`).

```{r}
#actual outcome in treated
tib_y_tr_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$Y.tr %>% 
  as_tibble() %>%
  mutate(year=row_number()+1999) %>% 
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>% 
  rename(
    state_id = name,
    y_tr_pt = value #observed treated value, pt for point estimate
  ) %>% 
  mutate(state_id =as.numeric(state_id))
  
  
# Counterfactual outcome in treated
tib_y_ct_mc_nnm=gsynth_out_overall_sub_pol_mc_nnm$Y.ct %>% 
  as_tibble() %>%
  mutate(year=row_number()+1999) %>% 
  dplyr::select(year,everything()) %>% 
  pivot_longer(cols=-year) %>% 
  rename(
    state_id = name,
    y_ct_pt = value#estimated counterfactual value, pt for point estimate
  ) %>% 
  mutate(state_id =as.numeric(state_id))
```

Link them together with the treatment-status indicator and find differences and ratios
```{r}
tib_mc_nnm=tib_treatedpost %>% 
  left_join(tib_y_tr_mc_nnm,by=c("year","state_id")) %>% 
  left_join(tib_y_ct_mc_nnm,by=c("year","state_id")) %>% 
  left_join(tib_diff_eff_by_state_year_mc_nnm,by=c("year","state_id")) %>% 
  #Check to make sure that the difference calculated
  #by subtracting the observed outcome from the counterfactual outcome
  #is the same as the reported state-year effect estimates. 
  #Rename the difference effect reported by .eff
  rename(diff_pt_report=diff_pt) %>% 
  #Calculate differences and ratios
  mutate(
      diff_pt=y_tr_pt-y_ct_pt,#difference effect (point estimate)
      ratio_pt=y_tr_pt/y_ct_pt, #Ratio effect (point estimate)
      
#      As a check, are these the same?
      diff_pt_check=diff_pt_report-diff_pt

  )
  

tib_mc_nnm
```

As a check on these calculations, `diff_pt_check` should be zero in all observations
```{r}
summary(tib_mc_nnm$diff_pt_check)
```

We can now calculate average ratio effects in the treated over treated state-years. The ratio effect estimand of interest is the mean of the observed outcome in the treated divided by the mean of the countefactual outcome in the treated. In general, the arithmetic mean of ratios is not generally the same as the ratio of arithmetic means, so we should not take the arithmetic mean of the state-year ratio effects,  We can find the summary ratio effect by finding the mean of treated counterfactual outcomes in the treated state-years and the mean of observed outcomes in the treated state-years and then taking the ratio of those two means.

```{r}
ratio_pt_mc_nnm=tib_mc_nnm %>% 
  filter(treatedpost==1) %>% 
  group_by(treatedpost) %>% 
  summarise(
    y_tr_pt_mean=mean(y_tr_pt,na.rm=T),#observed treated value
    y_ct_pt_mean=mean(y_ct_pt,na.rm=T),#counterfactual 
  ) %>% 
  ungroup() %>% 
  mutate(
    ratio_pt_mean=y_tr_pt_mean/y_ct_pt_mean #ratio effect, point estimate
  )

ratio_pt_mc_nnm
```

This estimated ratio effect of 0.99 corresponds to the reported overall ratio effect for scenario 4 in the table in the main text.


### Confidence intervals
As we did for difference effects, we can calculate confidence intervals around this ratio effect by calculating the ratio effect in each bootstrap replicate and then finding the 2.5th and 97.5th percentiles over replicates.

In each replicate, we can calculate the estimated counterfactual outcome by subtracting the bootstrap's difference effect from the observed outcome. 
```{r}
#We can work from the previous tibble we created corresponding to the difference-based 
#bootstrapped effect estimates
ratio_ci_mc_nnm=tib_eff_boot_mc_nnm %>% 
  left_join(tib_mc_nnm,by=c("state_id","year")) %>% #link in the data just above
  filter(treatedpost==1) %>% #limit to treated observations
  mutate(
    y_ct_boot=y_tr_pt-diff_boot #counterfactual estimate - bootstrap
  ) %>% 
  #now calculate summary ratio effect in each replicate
  group_by(boot_rep, treatedpost) %>% 
  summarise(
      y_tr_pt_mean=mean(y_tr_pt,na.rm=T),#observed treated value, mean (doesn't vary by boot rep)
      y_ct_boot_mean=mean(y_ct_boot,na.rm=T)
  ) %>% 
  ungroup() %>% 
  mutate(
    ratio_boot_mean=y_tr_pt_mean/y_ct_boot_mean
  ) %>% 
    #Now return the 95% confidence intervals of the mean bootstrapped 
  #difference effect over replicates
  group_by(treatedpost) %>% 
  summarise(
      ratio_pt_ll=quantile(ratio_boot_mean, probs=0.025, na.rm=TRUE),
      ratio_pt_ul=quantile(ratio_boot_mean,probs=.975,na.rm=TRUE)
  )


```

Ratio effect point estimate
```{r}
ratio_pt_mc_nnm
```

Ratio effect 95% CI
```{r}
ratio_ci_mc_nnm
```



## Assess model fit before treatment
We can also assess model fit before treatment using the difference-based "effect" estimates before treatment. Before treatment, these differences are not effects but are the pre-treatment prediction error.

In the main text of the table, I used mean absolute error to measure model fit. Mean squared error or root mean squared error could also be used. I calculate these three measures below.

```{r}
#Let's begin with this tibble, which already contains all of the difference-based
#effect estimates
pre_tx_fit_mc_nnm=tib_mc_nnm %>% 
  mutate(
    #The mean absolute error is the mean of the absolute value of the difference-based
    #effect estimates before treatment.
    diff_pt_abs=abs(diff_pt),

    #To calculate mean squared error, we can first square the difference-based effect
    #estimates and then take the mean
    diff_pt_squared=diff_pt**2 
  ) %>% 
  filter(treatedpost==0) %>% #0 meaning pre-treatment
  group_by(treatedpost) %>% 
  summarise(
    diff_pt_abs_mean=mean(diff_pt_abs,na.rm=T),
    diff_pt_squared_mean=mean(diff_pt_squared,na.rm=T)
  ) %>% 
  mutate(
      #square root the square error
      diff_pt_root_mean_square=sqrt(diff_pt_squared_mean)
  )
```
The mean absolute error of 3.3 corresponds to the reported value for scenario 4 in the table in the main text
```{r}
pre_tx_fit_mc_nnm
```


## Weighted average treatment effects
When considering the overall population-level effect of the policy, it may be desirable to weight states proportional to their share of that total population (or, more precisely, person-time as there is a temporal component). In this section, I calculate a weighted-average treatment effect, weighting each treated state-year's effect estimate by its share of treated person time. 

### Exploring weights

The weights for a given state-year are that state-year's proportion of the total treated person-years among adults aged 45-64 (variable name: `prop_of_tot_pop_year`). I gathered state-year populations of adults aged 45-64 from the American Community Survey. These scripts have more details on that:

* scripts/read-wrangle-data-acs.R
* scripts/read-wrangle-data-nianogo-et-al.R

Here a histogram of the weights in the treated state-years.
```{r}
setwd(here("data","data-processed"))
load("state_year_wts_overall.RData")
state_year_wts_overall %>% 
  ggplot(aes(prop_of_tot_pop_year))+
  geom_histogram()+
  theme_bw()
```

Each observation in this dataset of weights is a state-year. The weights add up to 1 over treated state-years.
```{r}
state_year_wts_overall
state_year_wts_overall %>% 
  mutate(dummy=1) %>% 
  group_by(dummy) %>% 
  summarise(prop_of_tot_pop_year=sum(prop_of_tot_pop_year))
```

Here's a map of the weights in 2019. In a given year, they do not sum to 1 because they sum to 1 over all treated state-years.
```{r}
setwd(here("data","data-processed"))
load("lookup_state_id_state_abb.RData")
state_year_wts_overall_2019=state_year_wts_overall %>% 
  filter(year==2019)
lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(lookup_state_id_state_abb,by="state_abb") %>% 
  left_join(state_year_wts_overall_2019,by="state_id") %>% 
  tm_shape()+
  tm_fill(
        "prop_of_tot_pop_year",
        palette =viridis(n=5),
  title="Share of person-years")+
  tm_borders(col="black",alpha=1)+
    tm_layout(
    frame=F,
#    legend.title.size=.5,
    legend.outside=T,
    legend.outside.position="bottom"
    )
```

The same map in 2014. There are fewer states with non-missing data in this map because fewer states had expanded Medicaid in 2014.
```{r}
setwd(here("data","data-processed"))
load("lookup_state_id_state_abb.RData")
state_year_wts_overall_2014=state_year_wts_overall %>% 
  filter(year==2014)
lookup_state_abb_geo_simplify_shift_al_hi %>% 
  left_join(lookup_state_id_state_abb,by="state_abb") %>% 
  left_join(state_year_wts_overall_2014,by="state_id") %>% 
  tm_shape()+
  tm_fill(
        "prop_of_tot_pop_year",
        palette =viridis(n=5),
  title="Share of person-years")+
  tm_borders(col="black",alpha=1)+
    tm_layout(
    frame=F,
#    legend.title.size=.5,
    legend.outside=T,
    legend.outside.position="bottom"
    )
```

### Weighting effect estimates
We can use these weights to weight each treated year's effect estimate to calculate a weighted average treatment effect.

Work from the `tib_mc_nnm` tibble created above, which contains the following for each state-year estimated by the MC-NNM estimator:
* counterfactual outcome
* observed outcome
* estimated difference effect
* estimated ratio effect
* treatment status indicator

To this dataset, we will add the weights (`prop_of_tot_pop_year`, described above), joining by year and state identifier. To calculate the weighted-mean difference effect, we can take the weighted average of the constituent difference effects over treatment status (`treatedpost`) using base R's `weighted.mean()` function.

To calculate the weighted ratio effect, we first calculate weighted-average counterfactual and observed outcomes and then take the ratio of those.
```{r}
tib_mc_nnm %>% 
  left_join(state_year_wts_overall,by=c("state_id","year")) %>% 
  filter(treatedpost==1) %>% 
  group_by(treatedpost) %>% 
  summarise(
    
    #weighted mean difference effect
    diff_pt_mean_wt=weighted.mean(
      x=diff_pt,
      w=prop_of_tot_pop_year,#proportion of total population-years
      na.rm=T),
    
    #unweighted mean difference effect for comparison
    diff_pt_mean_unwt=mean(diff_pt,na.rm=T), 

    #weighted average observed outcome
      y_tr_pt_mean_wt=weighted.mean(
        x=y_tr_pt,
        w=prop_of_tot_pop_year, 
        na.rm=T),
    
    #weighted average counterfactual outcome
    y_ct_pt_mean_wt=weighted.mean(
        x=y_ct_pt,
        w=prop_of_tot_pop_year, 
        na.rm=T)
    ) %>% 
  ungroup() %>% 
  mutate(
    #Calculate ratio of the weighted observed outcome to weighted counterfactual outcome
    ratio_pt_mean_wt=y_tr_pt_mean_wt/y_ct_pt_mean_wt
  ) %>% 
  dplyr::select(-starts_with("treated")) %>% #remove this column for space
  knitr::kable(
    caption="Weighted average treatment effects in treated",
    digits=2)
```

Confidence intervals can be calculated analogously, first calculating the above measures in every bootstrap replicate and then taking the percentiles over replicates.
```{r}
tib_eff_boot_mc_nnm %>% 
  left_join(tib_mc_nnm,by=c("state_id","year")) %>% #link in the data just above
  left_join(state_year_wts_overall,by=c("state_id","year")) %>% 
  filter(treatedpost==1) %>% #limit to treated observations
  mutate(
    y_ct_boot=y_tr_pt-diff_boot #counterfactual estimate - bootstrap
  ) %>% 
  #calculate weighted averages in each replicate
  group_by(boot_rep, treatedpost) %>%
  summarise(
    
      #mean of the counterfactual estimate in the bootstrap rep
      #Unweighted
      y_ct_boot_mean_wt=weighted.mean(
        x=y_ct_boot,
        w=prop_of_tot_pop_year,
        na.rm=T),
      
      #calculate this again (doesn't change between reps)
      y_tr_pt_mean_wt=weighted.mean(
        x=y_tr_pt,
        w=prop_of_tot_pop_year,
        na.rm=T)
  ) %>% 
  ungroup() %>% 
  mutate(
    #weighted differences and ratios in each replicate
    ratio_boot_mean_wt=y_tr_pt_mean_wt/y_ct_boot_mean_wt,
    diff_boot_mean_wt=y_tr_pt_mean_wt-y_ct_boot_mean_wt
  ) %>% 
  #Find percentiles over replicates
  group_by(treatedpost) %>% 
  summarise(
      diff_pt_wt_ll=quantile(diff_boot_mean_wt, probs=0.025, na.rm=TRUE),
      diff_pt_wt_ul=quantile(diff_boot_mean_wt,probs=.975,na.rm=TRUE),
      
      ratio_pt_wt_ll=quantile(ratio_boot_mean_wt, probs=0.025, na.rm=TRUE),
      ratio_pt_wt_ul=quantile(ratio_boot_mean_wt,probs=.975,na.rm=TRUE)

  ) %>% 
  ungroup() %>% 
  knitr::kable(
    caption="95% CIs for weighted average treatment effects in treated",
    digits=2)
```



# Support for in-text statements
This section includes supporting information for some statements that I made in the text.

## Negative predicted counterfactual outomes in some groups
I stated the following in the main text: "the minimum predicted value of the counterfactual outcome in the treatment period over the replicates for the Hispanic population in Scenario 2 was −6091 CVD deaths per 100,000 adults."

The gsynth model output for the Hispanic population under Scenario 2 is created here:
gsynth-nianogo-et-al/scripts/gsynth-analyses-to-post.R

I'm loading its cleaned-up output here
```{r}
setwd(here("data","data-processed"))
load("gsynth_out_tib_hispanic_sub_pol.RData")
```

Below is the distribution of the predicted counterfactual outcomes. The minimum value is below zero, which is not plausible for a mortality rate.
```{r}
summary(gsynth_out_tib_hispanic_sub_pol$y_ct_boot)
gsynth_out_tib_hispanic_sub_pol %>% 
  ggplot(aes(x=y_ct_boot))+
  geom_histogram()+
  theme_bw()
```


## Implausible demographic values
In the main text, I also noted that there were implausible values in age-group-race subgroups. I stated that, "in one state-year, the data state that 100% of Hispanic adults aged 45 to 64 years were men, while in another state-year, 0% were."

The histograms in the sub-section titled "Exploring data">"Distribution of BRFSS covariates">"Proportion men" shows that data. Copied here:

```{r,eval=T, echo=F, warning=FALSE, message=F}
summary(hispanic_complete$male)
hispanic_complete %>% 
  ggplot(aes(x=male))+
  geom_histogram()+
  theme_bw()
```

## State-by-state share of total person-years of adults aged 45-64
In the text, I stated, "Considering the total population of adults aged 45 to 64 years, for example, there were 309,495,338 person-years over all treated states and years. California contributed the largest share (19.1%) to this total. Considering Black adults in this age range, the state of New York contributed the largest share (15.8%) of the 29,839,638 total treated person-years available for analysis."

Total person-years of adults aged 45-64 over all treated states and years
```{r}
setwd(here("data","data-processed"))
load("state_year_wts_overall.RData")
state_year_wts_overall %>% slice(1) %>% pull(pop_tot_all_treated_years)
```

Share of that total contributed by each state
```{r}
state_year_wts_overall  %>%
  left_join(lookup_state_id_state_abb,by="state_id") %>%
  dplyr::select(state_abb,everything()) %>%
  group_by(state_abb) %>% 
  summarise(prop_of_tot_pop_year=sum(prop_of_tot_pop_year,na.rm=T)) %>% 
  ungroup() %>% 
  arrange(desc(prop_of_tot_pop_year))
```


Total person-years of Black adults aged 45-64 over all treated states and years
```{r}
setwd(here("data","data-processed"))
load("state_year_wts_race_b.RData")
state_year_wts_race_b %>% slice(1) %>% pull(pop_tot_all_treated_years)
```

Share of that total contributed by each treated state
```{r}
state_year_wts_race_b %>%
  left_join(lookup_state_id_state_abb,by="state_id") %>%
  dplyr::select(state_abb,everything()) %>%
  group_by(state_abb) %>% 
  summarise(prop_of_tot_pop_year=sum(prop_of_tot_pop_year,na.rm=T)) %>% 
  ungroup() %>% 
  arrange(desc(prop_of_tot_pop_year))
```






